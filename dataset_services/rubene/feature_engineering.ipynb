{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "1. Select low/high-variance variables\n",
    "2. Dropping redundant variables\n",
    "3. RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nr records=100000 nr variables=32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dslabs_functions as dslabs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.pyplot import subplots, show\n",
    "from matplotlib.pyplot import savefig, figure\n",
    "\n",
    "## tratar da primeira coluna nos notebooks anteriores\n",
    "winning_alternative_scaling = 2\n",
    "folder = \"feat_eng_csvs\"\n",
    "filename = f'../data_preparation_csvs/scaling_csvs/data_scaled_minmax_alt2.csv'\n",
    "data_scaling: pd.DataFrame = pd.read_csv(filename, sep=',', decimal='.', na_values='')\n",
    "print(f\"Dataset nr records={data_scaling.shape[0]}\", f\"nr variables={data_scaling.shape[1]}\")\n",
    "filename_prefix = \"../data_preparation_csvs/outliers_treatment_csvs/feature_eng_\"\n",
    "\n",
    "train = pd.read_csv('../data_preparation_csvs/scaling_csvs/train_data_scaled_minmax_alt2.csv')\n",
    "test = pd.read_csv('../data_preparation_csvs/scaling_csvs/test_data_scaled_minmax_alt2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "def save(df, name):\n",
    "    df.to_csv(f'{filename_prefix}{name}_data.csv', index=False)\n",
    "\n",
    "    ## Separate into Train and Test and save in different files\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    ## Save the training and testing sets to CSV files\n",
    "    train_data.to_csv(f'../data_preparation_csvs/{folder}/train_data_mv_{name}.csv', index=False)\n",
    "    test_data.to_csv(f'../data_preparation_csvs/{folder}/test_data_mv_{name}.csv', index=False)\n",
    "\n",
    "    ## Evaluate Approach\n",
    "    file_tag = \"Credit_Score\"\n",
    "    target = \"Credit_Score\"\n",
    "\n",
    "    figure()\n",
    "    eval: dict[str, list] = dslabs.evaluate_approach(train_data, test_data, target=target, metric=\"recall\")\n",
    "    dslabs.plot_multibar_chart(\n",
    "        [\"NB\", \"KNN\"], eval, title=f\"{file_tag} evaluation\", percentage=True\n",
    "    )\n",
    "    savefig(f\"../data_preparation_images/{folder}_result/data_mv_{name}_eval.png\")\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original variables ['Month', 'Occupation', 'Payment_of_Min_Amount', 'CreditMix', 'Payment_Behaviour', 'Payday Loan', 'Personal Loan', 'Debt Consolidation Loan', 'Auto Loan', 'Not Specified Loan', 'Student Loan', 'Credit-Builder Loan', 'Mortgage Loan', 'Home Equity Loan', 'Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'NumofLoan', 'Delay_from_due_date', 'NumofDelayedPayment', 'ChangedCreditLimit', 'NumCreditInquiries', 'OutstandingDebt', 'CreditUtilizationRatio', 'Credit_History_Age', 'TotalEMIpermonth', 'Amountinvestedmonthly', 'MonthlyBalance', 'Credit_Score']\n",
      "Variables to drop ['Annual_Income', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'NumofLoan', 'NumofDelayedPayment', 'NumCreditInquiries', 'TotalEMIpermonth', 'Amountinvestedmonthly']\n",
      "9 32\n"
     ]
    }
   ],
   "source": [
    "target = \"Credit_Score\"\n",
    "file_tag = \"Credit_Score\"\n",
    "print(\"Original variables\", train.columns.to_list())\n",
    "vars2drop: list[str] = dslabs.select_low_variance_variables(train, 0.015, target=target)\n",
    "print(\"Variables to drop\", vars2drop)\n",
    "print(len(vars2drop), len(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Credit_Score\"\n",
    "file_tag = \"Credit_Score\"\n",
    "\n",
    "eval_metric = \"recall\"\n",
    "figure(figsize=(2 * dslabs.HEIGHT, dslabs.HEIGHT))\n",
    "print(dslabs.study_variance_for_feature_selection(\n",
    "    train,\n",
    "    test,\n",
    "    target=target,\n",
    "    max_threshold=0.015,\n",
    "    lag=0.01,\n",
    "    metric=eval_metric,\n",
    "    file_tag=file_tag,\n",
    "))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = pd.DataFrame(data={'NB': [0.8305960639954694, 0.8717966869602152, 0.8874415970550757, 0.8874415970550757, 0.8873000141582896, 0.8873708056066827, 0.8908395865779414, 0.8908395865779414, 0.8905564207843693, 0.8905564207843693], 'KNN': [0.8912643352682996, 0.8824861956675634, 0.877530794280051, 0.877601585728444, 0.8785926660059464, 0.8948746991363443, 0.8945207418943791, 0.8945207418943791, 0.9318278351975081, 0.9318278351975081]}\n",
    ")\n",
    "\n",
    "print(vals[\"KNN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original variables\", train.columns.values)\n",
    "vars2drop: list[str] = dslabs.select_redundant_variables(\n",
    "    train, target=target, min_threshold=0.54\n",
    ")\n",
    "print(\"Variables to drop\", vars2drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables to drop ['Payment_of_Min_Amount', 'Delay_from_due_date']\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.5\n",
      "        ... \n",
      "79995    0.0\n",
      "79996    1.0\n",
      "79997    0.5\n",
      "79998    0.0\n",
      "79999    0.5\n",
      "Name: Payment_of_Min_Amount, Length: 80000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "options: list[float] = [\n",
    "    round(0.5 + i * 0.01, 3)\n",
    "    for i in range(ceil((1 - 0.5) / 0.01) + 1)\n",
    "]\n",
    "                                                # OPTIMAL VALUE: 0.54 (2 cols dropped)\n",
    "\n",
    "vars2drop: list[str] = dslabs.select_redundant_variables(\n",
    "    train, target=target, min_threshold=0.54\n",
    ")\n",
    "print(\"Variables to drop\", vars2drop)\n",
    "df = train.copy()\n",
    "df.drop(columns=vars2drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NB': [0.8443983402489627], 'KNN': [1.0]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_metric = \"recall\"\n",
    "\n",
    "new_train = train.copy()\n",
    "new_train.drop(columns=vars2drop)\n",
    "new_test = train.copy()\n",
    "new_test.drop(columns=vars2drop)\n",
    "\n",
    "figure(figsize=(2 * dslabs.HEIGHT, dslabs.HEIGHT))\n",
    "print(dslabs.study_redundancy_for_feature_selection(\n",
    "    new_train,\n",
    "    new_test,\n",
    "    target=target,                      # RECALL DE 1 NO KNN WTF NNGAGNGNAGNANGANGA\n",
    "    metric=eval_metric,\n",
    "    file_tag=file_tag,\n",
    "))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for LogisticRegression:\n",
      "Index(['Payment_of_Min_Amount', 'CreditMix', 'Payment_Behaviour',\n",
      "       'Payday Loan', 'Debt Consolidation Loan', 'Auto Loan',\n",
      "       'Not Specified Loan', 'Student Loan', 'Mortgage Loan',\n",
      "       'Monthly_Inhand_Salary', 'Delay_from_due_date', 'ChangedCreditLimit',\n",
      "       'OutstandingDebt', 'Credit_History_Age', 'Amountinvestedmonthly',\n",
      "       'Credit_Score'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Selected Features for RandomForestClassifier:\n",
      "Index(['CreditMix', 'Annual_Income', 'Monthly_Inhand_Salary',\n",
      "       'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'NumofLoan',\n",
      "       'Delay_from_due_date', 'NumofDelayedPayment', 'ChangedCreditLimit',\n",
      "       'NumCreditInquiries', 'OutstandingDebt', 'Credit_History_Age',\n",
      "       'TotalEMIpermonth', 'MonthlyBalance', 'Credit_Score'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Selected Features for GradientBoostingClassifier:\n",
      "Index(['Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n",
      "       'Num_Credit_Card', 'Interest_Rate', 'NumofLoan', 'Delay_from_due_date',\n",
      "       'NumofDelayedPayment', 'NumCreditInquiries', 'OutstandingDebt',\n",
      "       'CreditUtilizationRatio', 'Credit_History_Age', 'TotalEMIpermonth',\n",
      "       'Amountinvestedmonthly', 'MonthlyBalance', 'Credit_Score'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is loaded into a pandas DataFrame 'data'\n",
    "# 'target_column' refers to the column you want to predict/classify\n",
    "\n",
    "# Replace these with your actual data and target column\n",
    "target_column = 'Credit_Score'  # Your target column name\n",
    "\n",
    "X = data_scaling.copy()\n",
    "X.drop(columns=[\"Credit_Score\"])\n",
    "\n",
    "y = data_scaling[target]\n",
    "\n",
    "# List of models to test\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform RFE\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    rfe = RFE(model)  # Adjust the number of features as needed\n",
    "    rfe.fit(X, y)\n",
    "    selected_features = X.columns[rfe.support_]\n",
    "    print(f\"Selected Features for {model_name}:\")\n",
    "    print(selected_features)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
